name: Weather Scraper & Deploy

on:
  schedule:
    - cron: '*/15 * * * *'  # every 15 minutes
  workflow_dispatch:        # manual trigger
  push:
    branches: [ "main" ]

permissions:
  contents: write  # needed for auto-commit

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: "3.10"

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install chromedriver-autoinstaller selenium pytz

    - name: Install Chrome
      run: |
        sudo apt update
        wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
        sudo apt install -y ./google-chrome-stable_current_amd64.deb

    - name: Run weather scraper
      run: python weather_scraper.py

    - name: Auto-commit updated CSV
      run: |
        git config --global user.name "github-actions"
        git config --global user.email "github-actions@github.com"
        git add public/weather_log.csv
        git commit -m "Update weather_log.csv [auto]" || echo "No changes to commit"

    - name: Push CSV changes to main
      run: |
        git pull --rebase origin main || echo "Already up to date"
        git push origin main || echo "Nothing to push"

    - name: Setup Node
      uses: actions/setup-node@v3
      with:
        node-version: '20'

    - name: Install Node Dependencies
      run: npm install

    - name: Build
      run: npm run build

    - name: Deploy to GitHub Pages
      uses: peaceiris/actions-gh-pages@v4
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_dir: ./dist
        publish_branch: gh-pages-build
